# -*- coding: utf-8 -*-
"""
Created on Fri Jul 30 18:11:57 2021

@author: fhu14

Driver file that goes through the entire precompute stage to precompute
datasets of the form needed for passing through the model

This driver works with ANI-like datasets which organizes the data in a
hierarchical dictionary interface

The precompute workflow consists of two separate stages:
    1) Generating the molecule folds. These are stored as pickle files
        with the naming convention "Fold{num}_molecs.p"
    2) Running those folds through the precompute and 
"""
#%% Imports, definitions
from FoldManager import generate_folds, save_folds, compute_graphs_from_folds,\
    precompute_gammas, precompute_gammas_per_fold, randomize_existing_set
from InputParser import parse_input_dictionaries, collapse_to_master_settings, inflate_to_dict
import pickle
from typing import List, Dict
import time

#%% Code behind

def generate_save_folds(allowed_Zs: List[int], heavy_atoms: List[int], max_config: int, 
                   target: Dict[str, str], data_path: str, exclude: List[str], lower_limit: int, 
                   num_folds: int, num_folds_lower: int, dest: str, randomize: bool) -> None:
    r"""Generates and saves the fold pickle files
    
    Arguments:
        allowed_Zs (List[int]): The allowed elements in the dataset
        heavy_atoms (List[int]): The allowed heavy (non-hydrogen) atoms
        max_config (int): The maximum number of configurations
        target (Dict): Dictionary mapping the target names (e.g. 'Etot') to the 
            ani1 target names (e.g. 'cc')
        data_path (str): The relative path to the dataset from which to pull molecules
        exclude (List[str]): The molecular formulas to exclude when pulling the dataset
        lower_limit (int): The number of heavy atoms to include up to for the folds containing
            lower heavy elements (e.g. folds up to 5)
        num_folds (int): The total number of folds
        num_folds_lower (int): The number of folds that contain molecules with heavy atoms
            only up to lower_limit
        dest (str): Path to the location to save the folds
        randomize (bool): Whether or not to randomize the dataset so that 
            folds are not separated based on nheavy
    
    Returns:
        None
    
    Notes: By default, the folds generated by generate_folds() is separated 
        into folds based on nheavy, but these can be randomized into folds
        not separated by nheavy if the randomize flag is set to true.
    """
    folds = generate_folds(allowed_Zs, heavy_atoms, max_config, target, data_path,
                           exclude, lower_limit, num_folds, num_folds_lower)
    save_folds(folds, dest)
    if randomize:
        print("Randomizing folds")
        randomize_existing_set(dest, dest) #Randomized files are kept in the same directory
    print("Folds generated")

def precompute_folds(s, opts: Dict, top_level_molec_path: str, copy_molecs: bool) -> None:
    r"""Executes the graph/feed generation and saving portion of the 
        precompute workflow
    
    Arguments:
        s (Settings): The settings object containing all the hyperparameter values
        opts (Dict): The dictionary used by the DFTBrepulsive model that contains
            hyperparameter settings of interest
        top_level_molec_path (str): The relative path to the directory containing 
            the molecules of each fold
        copy_molecs (bool): Whether or not to duplicate the raw molecule pickle files
            in the directories with the saved h5 files 
    
    Returns: 
        None
    
    Notes: The fields of s that matter are as follows:
        1) par_dict_name (Dict): The parameter dictionary for calculations
        2) train_ener_per_heavy (bool): Whether energies are trained per heavy atom
        3) opers_to_model (List[str]): The list of operators to model
        4) allowed_Zs (List[int]): The allowed elements in the molecules of the dataset
        5) num_per_batch (int): The number of molecules to have per batch
        6) losses (List[str]): The list of targets to include in the loss function
        7) target_accuracy_[loss] (float): The weight given to each loss contained
            in losses.
        8) tensor_device (torch.device): The device to use for generated tensors
        9) tensor_dtype (torch.dtype): The dtype to use for your generated tensors
        10) reference_energy_starting_point (List[float]): The reference energy
            parameters to use
        11) low_end_correction_dict (Dict): Dictionary containing low ends of ranges for
            atom pairs.
        12) universal_high (float): The maximal range for all atom pairs
        13) spline_mode (str): The mode of splines to use
        14) spline_deg (int): The degree of the spline to use
        15) debug (bool): Whether or not debugging mode is being used. Should 
            always be set to false.
        16) num_knots (int): The number of knots for the splines
        17) buffer (float): How much to extend the ends of the spline range by
        18) joined_cutoff (float): The cutoff point for splines 
        19) cutoff_dictionary (Dict): The dictionary indicating the cutoffs for
            different element pairs
        20) off_diag_opers (List[str]): The operators to be modeled differently
            than a normal univariate spline (i.e. hubbard G)
        21) include_inflect (bool): Whether the inflection point penalty should be 
            included for the S (overlap) operators.
        
        In addition to computing the graphs and feeds for the folds, also 
        precomputes and saves the gammas and configuration trackers, both 
        in total for the dataset and per fold.
    """
    compute_graphs_from_folds(s, top_level_molec_path, copy_molecs)
    precompute_gammas(opts, top_level_molec_path)
    precompute_gammas_per_fold(opts, top_level_molec_path)
    print("Fold precomputation done")

def precompute_main(settings_filename: str, defaults_filename: str, lower_limit: int, 
                   num_folds: int, num_folds_lower: int, randomize: bool, copy_molecs: bool,
                   generate_folds: bool = True) -> None:
    r"""Main method that generates a dataset of the form necessary for passing through 
        the model
    
    Arguments:
        settings_filename (str): The path to the setting file of .json format
        defaults_filename (str): The path to the defaults file of .json format
        lower_limit (int): The number of heavy atoms to include up to for the folds containing
            lower heavy elements (e.g. folds up to 5)
        num_folds (int): The total number of folds
        num_folds_lower (int): The number of folds that contain molecules with heavy atoms
            only up to lower_limit
        randomize (bool): Whether or not to randomize the dataset so that 
            folds are not separated based on nheavy
        copy_molecs (bool): Whether or not to duplicate the raw molecule pickle files
            in the directories with the saved h5 files 
        generate_folds (bool): Whether or not to generate the folds (pickle files of 
             molecule dictionaries). Defaults to True.
    
    Returns:
        None
    
    Notes: Certain fields are interpreted from the settings file. Specifically:
        allowed_Zs (List[int])
        heavy_atoms (List[int])
        max_config (int)
        target (Dict)
        data_path (str)
        exclude (List[str])
        dest (str) (taken from s.top_level_fold_path)
        
        Be sure that these fields are properly set, along with the fields
        mentioned in the docstring of precompute_folds
    """
    #Initialize the settings objects and dictionaries
    resulting_settings_obj = parse_input_dictionaries(settings_filename, defaults_filename)
    opts = inflate_to_dict(resulting_settings_obj)
    s = collapse_to_master_settings(resulting_settings_obj)
    #Generate and save the folds
    if generate_folds:
        generate_save_folds(s.allowed_Zs, s.heavy_atoms, s.max_config, s.target, 
                            s.data_path, s.exclude, lower_limit, num_folds, num_folds_lower, s.top_level_fold_path, 
                            randomize)
    #Do the precompute
    precompute_folds(s, opts, s.top_level_fold_path, copy_molecs)
    print("Precompute workflow complete")

#%% Main block
if __name__ == '__main__':
    settings_filename = "settings_refactor_tst.json"
    defaults_filename = "refactor_default_tst.json"
    lower_limit = 5
    num_folds = 6
    num_folds_lower = 3
    randomize = True
    copy_molecs = True
    gen_folds = False
    
    start = time.time()
    precompute_main(settings_filename, defaults_filename, lower_limit, num_folds,
                    num_folds_lower, randomize, copy_molecs, gen_folds)
    end = time.time()
    print(f"time elapsed is {end - start} for sequential")
    
    


